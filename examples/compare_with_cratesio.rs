use cratespro_search::search::{RecommendCrate, SearchModule, SearchSortCriteria};
use dotenv::dotenv;
use prettytable::{format, Cell, Row, Table};
use reqwest::Client;
use serde::{Deserialize, Serialize};
use std::collections::HashMap;
use std::env;
use std::fs::File;
use std::io::Write;
use std::sync::Arc;
use std::time::Instant;
use tokio_postgres::NoTls;

// LLMç›¸å…³çš„æ•°æ®ç»“æ„
#[derive(Debug, Deserialize, Serialize)]
struct LLMMessage {
    role: String,
    content: String,
}

#[derive(Debug, Deserialize, Serialize)]
struct LLMResponseChoice {
    message: LLMMessage,
}

#[derive(Debug, Deserialize, Serialize)]
struct LLMResponse {
    choices: Vec<LLMResponseChoice>,
}

#[derive(Debug, Deserialize, Serialize)]
struct LLMRequest {
    model: String,
    messages: Vec<LLMMessage>,
    temperature: f32,
}

#[derive(Debug, Deserialize, Serialize)]
struct RelevanceJudgment {
    crate_name: String,
    is_relevant: bool,
    confidence: f32,
    reasoning: String,
}

#[derive(Debug, Deserialize, Serialize)]
struct LLMJudgmentResponse {
    judgments: Vec<RelevanceJudgment>,
}

// crates.io APIå“åº”ç»“æ„
#[derive(Debug, Deserialize)]
struct CratesIoCrate {
    id: String,
    name: String,
    description: Option<String>,
    downloads: i64,
    #[serde(rename = "max_version")]
    version: String,
}

#[derive(Debug, Deserialize)]
struct CratesIoResponse {
    crates: Vec<CratesIoCrate>,
    meta: CratesIoMeta,
}

#[derive(Debug, Deserialize)]
struct CratesIoMeta {
    total: i64,
}

// æµ‹è¯•ç”¨ä¾‹
#[derive(Debug, Deserialize, Serialize)]
struct TestCase {
    query: String,
    description: String,
}

// å®éªŒç»“æœ
#[derive(Debug, Serialize)]
struct ComparisonResult {
    query: String,
    description: String,
    method: String,
    precision_at_1: f64,
    precision_at_3: f64,
    precision_at_5: f64,
    precision_at_10: f64,
    precision_at_20: f64,
    relevant_count: i32,
    latency_ms: f64,
}

#[tokio::main]
async fn main() -> Result<(), Box<dyn std::error::Error>> {
    // åŠ è½½ç¯å¢ƒå˜é‡
    dotenv().ok();

    println!("ğŸ” å¼€å§‹LLMè¾…åŠ©æœç´¢ä¸crates.ioæœç´¢å¯¹æ¯”å®éªŒ");

    // ç¡®ä¿OpenAI APIå¯†é’¥å·²é…ç½®
    let api_key = env::var("OPENAI_API_KEY").expect("éœ€è¦è®¾ç½®OPENAI_API_KEYç¯å¢ƒå˜é‡");

    // è¿æ¥åˆ°æ•°æ®åº“
    let db_url = env::var("DATABASE_URL").expect("DATABASE_URL ç¯å¢ƒå˜é‡æœªè®¾ç½®");
    let (pg_client, connection) = tokio_postgres::connect(&db_url, NoTls).await?;

    // åœ¨åå°è¿è¡Œè¿æ¥
    tokio::spawn(async move {
        if let Err(e) = connection.await {
            eprintln!("æ•°æ®åº“è¿æ¥é”™è¯¯: {}", e);
        }
    });

    // åˆ›å»ºLLMè¾…åŠ©æœç´¢æ¨¡å—
    let llm_search = SearchModule::new(&pg_client).await;

    // åˆ›å»ºHTTPå®¢æˆ·ç«¯
    let http_client = Arc::new(Client::new());

    // ç¼“å­˜ä»¥é¿å…é‡å¤LLMè°ƒç”¨
    let mut relevance_cache = HashMap::new();

    // å®šä¹‰æµ‹è¯•ç”¨ä¾‹
    let test_cases = vec![
        TestCase {
            query: "http client".to_string(),
            description: "HTTPå®¢æˆ·ç«¯åº“".to_string(),
        },
        TestCase {
            query: "json".to_string(),
            description: "JSONå¤„ç†åº“".to_string(),
        },
        TestCase {
            query: "async runtime".to_string(),
            description: "å¼‚æ­¥è¿è¡Œæ—¶".to_string(),
        },
        TestCase {
            query: "cli".to_string(),
            description: "å‘½ä»¤è¡Œå·¥å…·".to_string(),
        },
        TestCase {
            query: "orm".to_string(),
            description: "å¯¹è±¡å…³ç³»æ˜ å°„".to_string(),
        },
        TestCase {
            query: "web framework".to_string(),
            description: "Webæ¡†æ¶".to_string(),
        },
        TestCase {
            query: "logging".to_string(),
            description: "æ—¥å¿—åº“".to_string(),
        },
    ];

    println!("ğŸ“‹ å‡†å¤‡äº† {} ä¸ªæµ‹è¯•ç”¨ä¾‹", test_cases.len());

    // å­˜å‚¨æ¯”è¾ƒç»“æœ
    let mut results = Vec::new();

    // å¯¹æ¯ä¸ªç”¨ä¾‹è¿›è¡Œæµ‹è¯•
    for test_case in &test_cases {
        println!(
            "\nğŸ“ æµ‹è¯•ç”¨ä¾‹: {} - \"{}\"",
            test_case.description, test_case.query
        );

        // LLMè¾…åŠ©æœç´¢
        println!("\n  ğŸ§  LLMè¾…åŠ©æœç´¢:");
        let llm_start = Instant::now();
        let llm_results = match llm_search
            .search_crate(&test_case.query, SearchSortCriteria::Comprehensive)
            .await
        {
            Ok(res) => res,
            Err(e) => {
                eprintln!("LLMæœç´¢é”™è¯¯: {}", e);
                continue;
            }
        };
        let llm_duration = llm_start.elapsed();

        // ä½¿ç”¨LLMè¯„ä¼°ç›¸å…³æ€§
        println!("  ğŸ” ä½¿ç”¨LLMè¯„ä¼°æœç´¢ç»“æœç›¸å…³æ€§...");
        let llm_relevance = evaluate_with_llm(
            &http_client,
            &test_case.query,
            &llm_results[..20.min(llm_results.len())],
            &api_key,
            &mut relevance_cache,
        )
        .await?;

        // ä½¿ç”¨LLMç›¸å…³æ€§åˆ¤æ–­è®¡ç®—æŒ‡æ ‡
        let llm_metrics = calculate_metrics_from_llm_judgments(&llm_results, &llm_relevance);

        println!("    â±ï¸ æœç´¢è€—æ—¶: {:.2?}", llm_duration);
        println!(
            "    P@1: {:.2}, P@3: {:.2}, P@5: {:.2}, P@10: {:.2}, P@20: {:.2}, ç›¸å…³ç»“æœ: {}",
            llm_metrics.0, llm_metrics.1, llm_metrics.2, llm_metrics.3, llm_metrics.4, llm_metrics.5
        );

        // æ‰“å°LLMæœç´¢çš„å‰5ä¸ªç»“æœåŠå…¶ç›¸å…³æ€§
        print_results_with_llm_judgments("LLMè¾…åŠ©æœç´¢", &llm_results, &llm_relevance, 5);

        // crates.ioæœç´¢
        println!("\n  ğŸŒ crates.ioæœç´¢:");
        let crates_io_start = Instant::now();
        let crates_io_results = fetch_crates_io_results(&http_client, &test_case.query).await?;
        let crates_io_duration = crates_io_start.elapsed();

        // å°†crates.ioç»“æœè½¬æ¢ä¸ºRecommendCrateæ ¼å¼ä»¥ä¾¿ä¸€è‡´å¤„ç†
        let crates_io_recommend = convert_to_recommend_crates(crates_io_results);

        // ä½¿ç”¨LLMè¯„ä¼°crates.ioæœç´¢ç»“æœç›¸å…³æ€§
        println!("  ğŸ” ä½¿ç”¨LLMè¯„ä¼°crates.ioæœç´¢ç»“æœç›¸å…³æ€§...");
        let crates_io_relevance = evaluate_with_llm(
            &http_client,
            &test_case.query,
            &crates_io_recommend[..20.min(crates_io_recommend.len())],
            &api_key,
            &mut relevance_cache,
        )
        .await?;

        // ä½¿ç”¨LLMç›¸å…³æ€§åˆ¤æ–­è®¡ç®—æŒ‡æ ‡
        let crates_io_metrics =
            calculate_metrics_from_llm_judgments(&crates_io_recommend, &crates_io_relevance);

        println!("    â±ï¸ æœç´¢è€—æ—¶: {:.2?}", crates_io_duration);
        println!(
            "    P@1: {:.2}, P@3: {:.2}, P@5: {:.2}, P@10: {:.2}, P@20: {:.2}, ç›¸å…³ç»“æœ: {}",
            crates_io_metrics.0,
            crates_io_metrics.1,
            crates_io_metrics.2,
            crates_io_metrics.3,
            crates_io_metrics.4,
            crates_io_metrics.5
        );

        // æ‰“å°crates.ioæœç´¢çš„å‰5ä¸ªç»“æœåŠå…¶ç›¸å…³æ€§
        print_results_with_llm_judgments(
            "crates.ioæœç´¢",
            &crates_io_recommend,
            &crates_io_relevance,
            5,
        );

        // è®°å½•ç»“æœ
        results.push(ComparisonResult {
            query: test_case.query.clone(),
            description: test_case.description.clone(),
            method: "LLMè¾…åŠ©æœç´¢".to_string(),
            precision_at_1: llm_metrics.0,
            precision_at_3: llm_metrics.1,
            precision_at_5: llm_metrics.2,
            precision_at_10: llm_metrics.3,
            precision_at_20: llm_metrics.4,
            relevant_count: llm_metrics.5 as i32,
            latency_ms: llm_duration.as_millis() as f64,
        });

        results.push(ComparisonResult {
            query: test_case.query.clone(),
            description: test_case.description.clone(),
            method: "crates.ioæœç´¢".to_string(),
            precision_at_1: crates_io_metrics.0,
            precision_at_3: crates_io_metrics.1,
            precision_at_5: crates_io_metrics.2,
            precision_at_10: crates_io_metrics.3,
            precision_at_20: crates_io_metrics.4,
            relevant_count: crates_io_metrics.5 as i32,
            latency_ms: crates_io_duration.as_millis() as f64,
        });
    }

    // ç”ŸæˆæŠ¥å‘Š
    generate_report(&results);

    // ä¿å­˜ç»“æœåˆ°æ–‡ä»¶
    if let Ok(mut file) = File::create("llm_vs_cratesio_comparison.json") {
        let json = serde_json::to_string_pretty(&results)?;
        file.write_all(json.as_bytes())?;
        println!("\nğŸ’¾ ç»“æœå·²ä¿å­˜åˆ° llm_vs_cratesio_comparison.json");
    }

    println!("\nâœ… å¯¹æ¯”å®éªŒå®Œæˆ");
    Ok(())
}

// ä»crates.io APIè·å–æœç´¢ç»“æœ
async fn fetch_crates_io_results(
    client: &Client,
    query: &str,
) -> Result<Vec<CratesIoCrate>, Box<dyn std::error::Error>> {
    // æ„å»ºcrates.io API URL
    let url = format!(
        "https://crates.io/api/v1/crates?page=1&per_page=20&q={}",
        urlencoding::encode(query)
    );

    // å‘é€è¯·æ±‚ - æ·»åŠ å¿…éœ€çš„User-Agentå¤´
    let response = client
        .get(&url)
        .header("User-Agent", "cratespro-search-experiment (github.com/cratespro-search)")
        .send()
        .await?;

    if !response.status().is_success() {
        let error_text = response.text().await?;
        return Err(format!("crates.io APIé”™è¯¯: {}", error_text).into());
    }

    // è§£æå“åº”
    let data: CratesIoResponse = response.json().await?;

    println!(
        "    ğŸ“Š crates.ioè¿”å›äº† {} ä¸ªç»“æœ (æ€»è®¡: {})",
        data.crates.len(),
        data.meta.total
    );

    Ok(data.crates)
}

// å°†crates.io APIå“åº”è½¬æ¢ä¸ºæˆ‘ä»¬çš„RecommendCrateæ ¼å¼
fn convert_to_recommend_crates(crates_io_crates: Vec<CratesIoCrate>) -> Vec<RecommendCrate> {
    crates_io_crates
        .into_iter()
        .map(|c| RecommendCrate {
            id: c.id,
            name: c.name,
            description: c.description.unwrap_or_default(),
            rank: 0.0,                       // æˆ‘ä»¬æ²¡æœ‰ç›´æ¥çš„æ’åä¿¡æ¯
            vector_score: 0.0,               // æ²¡æœ‰å‘é‡å¾—åˆ†
            final_score: c.downloads as f32, // ä½¿ç”¨ä¸‹è½½é‡ä½œä¸ºæœ€ç»ˆå¾—åˆ†
        })
        .collect()
}

// ä½¿ç”¨LLMåˆ¤æ–­æœç´¢ç»“æœçš„ç›¸å…³æ€§
async fn evaluate_with_llm(
    client: &Client,
    query: &str,
    results: &[RecommendCrate],
    api_key: &str,
    cache: &mut HashMap<String, HashMap<String, bool>>,
) -> Result<HashMap<String, bool>, Box<dyn std::error::Error>> {
    // æ£€æŸ¥ç¼“å­˜ï¼Œé¿å…é‡å¤è¯„ä¼°
    let cache_key = query.to_lowercase();
    if let Some(cached_judgments) = cache.get(&cache_key) {
        // å¦‚æœç¼“å­˜ä¸­æœ‰æ‰€æœ‰éœ€è¦çš„ç»“æœï¼Œç›´æ¥è¿”å›
        let all_cached = results
            .iter()
            .all(|r| cached_judgments.contains_key(&r.name.to_lowercase()));
        if all_cached {
            let mut filtered_judgments = HashMap::new();
            for result in results {
                if let Some(&is_relevant) = cached_judgments.get(&result.name.to_lowercase()) {
                    filtered_judgments.insert(result.name.clone(), is_relevant);
                }
            }
            return Ok(filtered_judgments);
        }
    }

    // ä¸ºé¿å…LLMä¸Šä¸‹æ–‡é•¿åº¦é™åˆ¶ï¼Œæ¯æ‰¹å¤„ç†5ä¸ªcrate
    let batch_size = 5;
    let mut all_judgments = HashMap::new();

    for chunk in results.chunks(batch_size) {
        // æ„å»ºæç¤ºï¼Œæè¿°æ¯ä¸ªcrateåŠå…¶åŠŸèƒ½
        let mut crates_description = String::new();
        for (i, crate_item) in chunk.iter().enumerate() {
            crates_description.push_str(&format!(
                "Crate {}: {} - {}\n",
                i + 1,
                crate_item.name,
                crate_item.description.replace('\n', " ")
            ));
        }

        // æ„å»ºå®Œæ•´çš„LLMæç¤º
        let system_prompt = "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„Rustç¼–ç¨‹åŠ©æ‰‹ï¼Œè´Ÿè´£è¯„ä¼°æœç´¢ç»“æœä¸æŸ¥è¯¢çš„ç›¸å…³æ€§ã€‚è¯·æ ¹æ®æŸ¥è¯¢å’Œæ¯ä¸ªcrateçš„æè¿°ï¼Œåˆ¤æ–­å®ƒä»¬æ˜¯å¦ç›¸å…³ã€‚";
        let user_prompt = format!(
            "æŸ¥è¯¢: \"{}\"\n\nä»¥ä¸‹æ˜¯æœç´¢ç»“æœ:\n{}\nè¯·å¯¹æ¯ä¸ªcrateè¿›è¡Œç›¸å…³æ€§åˆ¤æ–­ï¼Œè¿”å›JSONæ ¼å¼:\n{{\"judgments\": [{{\n  \"crate_name\": \"crateåç§°\",\n  \"is_relevant\": true/false,\n  \"confidence\": 0.0-1.0,\n  \"reasoning\": \"åˆ¤æ–­ç†ç”±\"\n}}, ...]}}\nåªè¿”å›JSONï¼Œä¸è¦æœ‰å…¶ä»–æ–‡å­—ã€‚",
            query, crates_description
        );

        // æ„å»ºAPIè¯·æ±‚
        let openai_url = env::var("OPEN_AI_CHAT_URL")
            .unwrap_or_else(|_| "https://api.openai.com/v1/chat/completions".to_string());

        let request = LLMRequest {
            model: "gpt-4-turbo".to_string(), // ä½¿ç”¨GPT-4ä»¥è·å¾—æ›´å¥½çš„åˆ¤æ–­
            messages: vec![
                LLMMessage {
                    role: "system".to_string(),
                    content: system_prompt.to_string(),
                },
                LLMMessage {
                    role: "user".to_string(),
                    content: user_prompt,
                },
            ],
            temperature: 0.2, // ä½æ¸©åº¦ä»¥ç¡®ä¿åˆ¤æ–­ä¸€è‡´æ€§
        };

        // å‘é€è¯·æ±‚
        let response = client
            .post(&openai_url)
            .header("Content-Type", "application/json")
            .header("Authorization", format!("Bearer {}", api_key))
            .json(&request)
            .send()
            .await?;

        if !response.status().is_success() {
            let error_text = response.text().await?;
            eprintln!("OpenAI APIé”™è¯¯: {}", error_text);
            return Err(format!("OpenAI APIè¿”å›é”™è¯¯: {}", error_text).into());
        }

        // è§£æå“åº”
        let response_data: LLMResponse = response.json().await?;
        if response_data.choices.is_empty() {
            return Err("LLMæ²¡æœ‰è¿”å›é€‰æ‹©ç»“æœ".into());
        }

        // æå–JSONå“åº”
        let content = &response_data.choices[0].message.content;

        // è§£æåˆ¤æ–­ç»“æœ
        let json_start = content.find('{');
        let json_end = content.rfind('}');

        if let (Some(start), Some(end)) = (json_start, json_end) {
            let json_content = &content[start..=end];
            // è§£æJSON
            match serde_json::from_str::<LLMJudgmentResponse>(json_content) {
                Ok(judgment_data) => {
                    // æ·»åŠ åˆ¤æ–­ç»“æœåˆ°æ€»ç»“æœä¸­
                    for judgment in judgment_data.judgments {
                        all_judgments.insert(judgment.crate_name.clone(), judgment.is_relevant);

                        // åŒæ—¶æ›´æ–°ç¼“å­˜
                        if !cache.contains_key(&cache_key) {
                            cache.insert(cache_key.clone(), HashMap::new());
                        }
                        if let Some(cache_map) = cache.get_mut(&cache_key) {
                            cache_map
                                .insert(judgment.crate_name.to_lowercase(), judgment.is_relevant);
                        }
                    }
                }
                Err(e) => {
                    eprintln!("JSONè§£æé”™è¯¯: {}. åŸå§‹å†…å®¹: {}", e, json_content);
                    // å°è¯•ä½¿ç”¨æ ¼å¼æ›´å®½æ¾çš„æ–¹å¼è§£æ
                    if let Ok(json_value) = serde_json::from_str::<serde_json::Value>(json_content)
                    {
                        if let Some(judgments) =
                            json_value.get("judgments").and_then(|j| j.as_array())
                        {
                            for judgment in judgments {
                                if let (Some(name), Some(relevant)) = (
                                    judgment.get("crate_name").and_then(|n| n.as_str()),
                                    judgment.get("is_relevant").and_then(|r| r.as_bool()),
                                ) {
                                    all_judgments.insert(name.to_string(), relevant);

                                    // æ›´æ–°ç¼“å­˜
                                    if !cache.contains_key(&cache_key) {
                                        cache.insert(cache_key.clone(), HashMap::new());
                                    }
                                    if let Some(cache_map) = cache.get_mut(&cache_key) {
                                        cache_map.insert(name.to_lowercase(), relevant);
                                    }
                                }
                            }
                        }
                    }
                }
            }
        } else {
            eprintln!("æ— æ³•è§£æLLMå“åº”ä¸­çš„JSON: {}", content);
        }
    }

    Ok(all_judgments)
}

// æ ¹æ®LLMåˆ¤æ–­è®¡ç®—æŒ‡æ ‡
fn calculate_metrics_from_llm_judgments(
    results: &[RecommendCrate],
    judgments: &HashMap<String, bool>,
) -> (f64, f64, f64, f64, f64, usize) {
    // æå–ç›¸å…³æ€§æ ‡å¿—
    let relevant_flags: Vec<bool> = results
        .iter()
        .map(|r| judgments.get(&r.name).copied().unwrap_or(false))
        .collect();

    // è®¡ç®—P@K
    let p1 = calculate_precision_at_k(&relevant_flags, 1);
    let p3 = calculate_precision_at_k(&relevant_flags, 3);
    let p5 = calculate_precision_at_k(&relevant_flags, 5);
    let p10 = calculate_precision_at_k(&relevant_flags, 10);
    let p20 = calculate_precision_at_k(&relevant_flags, 20);

    // è®¡ç®—ç›¸å…³ç»“æœæ•°é‡
    let relevant_count = relevant_flags
        .iter()
        .filter(|&&is_relevant| is_relevant)
        .count();

    (p1, p3, p5, p10, p20, relevant_count)
}

// è®¡ç®—Precision@K
fn calculate_precision_at_k(relevant_flags: &[bool], k: usize) -> f64 {
    if relevant_flags.is_empty() || k == 0 {
        return 0.0;
    }

    let k_actual = std::cmp::min(k, relevant_flags.len());
    let relevant_count = relevant_flags
        .iter()
        .take(k_actual)
        .filter(|&&is_relevant| is_relevant)
        .count();

    relevant_count as f64 / k_actual as f64
}

// æ‰“å°ç»“æœå¹¶æ˜¾ç¤ºLLMåˆ¤æ–­çš„ç›¸å…³æ€§
fn print_results_with_llm_judgments(
    method: &str,
    results: &[RecommendCrate],
    judgments: &HashMap<String, bool>,
    count: usize,
) {
    println!("    ğŸ“‹ {}çš„å‰{}ä¸ªç»“æœåŠç›¸å…³æ€§:", method, count);

    for (i, result) in results.iter().take(count).enumerate() {
        let is_relevant = judgments.get(&result.name).copied().unwrap_or(false);
        let mark = if is_relevant { "âœ“" } else { "âœ—" };

        println!(
            "      {}. {} {} - {}",
            i + 1,
            mark,
            result.name,
            truncate_text(&result.description, 40),
        );
    }
}

// ç”Ÿæˆå¯¹æ¯”æŠ¥å‘Š
fn generate_report(results: &[ComparisonResult]) {
    // åˆ›å»ºè¡¨æ ¼
    let mut table = Table::new();
    table.set_format(*format::consts::FORMAT_BOX_CHARS);

    // æ·»åŠ è¡¨å¤´
    table.add_row(Row::new(vec![
        Cell::new("æŸ¥è¯¢"),
        Cell::new("æ–¹æ³•"),
        Cell::new("P@1"),
        Cell::new("P@5"),
        Cell::new("P@10"),
        Cell::new("P@20"),
        Cell::new("ç›¸å…³æ•°é‡"),
        Cell::new("å»¶è¿Ÿ(ms)"),
    ]));

    // æ·»åŠ æ•°æ®è¡Œ
    for result in results {
        table.add_row(Row::new(vec![
            Cell::new(&truncate_text(
                &format!("{}({})", &result.query, &result.description),
                25,
            )),
            Cell::new(&result.method),
            Cell::new(&format!("{:.2}", result.precision_at_1)),
            Cell::new(&format!("{:.2}", result.precision_at_5)),
            Cell::new(&format!("{:.2}", result.precision_at_10)),
            Cell::new(&format!("{:.2}", result.precision_at_20)),
            Cell::new(&result.relevant_count.to_string()),
            Cell::new(&format!("{:.1}", result.latency_ms)),
        ]));
    }

    // æ‰“å°è¡¨æ ¼
    println!("\nğŸ“Š æœç´¢æ–¹æ³•å¯¹æ¯”ç»“æœ:");
    table.printstd();

    // è®¡ç®—å¹³å‡å€¼
    let llm_results: Vec<_> = results
        .iter()
        .filter(|r| r.method == "LLMè¾…åŠ©æœç´¢")
        .collect();

    let cratesio_results: Vec<_> = results
        .iter()
        .filter(|r| r.method == "crates.ioæœç´¢")
        .collect();

    if !llm_results.is_empty() && !cratesio_results.is_empty() {
        // è®¡ç®—å¹³å‡å€¼
        let avg_llm_p1 =
            llm_results.iter().map(|r| r.precision_at_1).sum::<f64>() / llm_results.len() as f64;
        let avg_llm_p5 =
            llm_results.iter().map(|r| r.precision_at_5).sum::<f64>() / llm_results.len() as f64;
        let avg_llm_p10 =
            llm_results.iter().map(|r| r.precision_at_10).sum::<f64>() / llm_results.len() as f64;
        let avg_llm_p20 =
            llm_results.iter().map(|r| r.precision_at_20).sum::<f64>() / llm_results.len() as f64;
        let avg_llm_relevant = llm_results.iter().map(|r| r.relevant_count).sum::<i32>() as f64
            / llm_results.len() as f64;
        let avg_llm_latency =
            llm_results.iter().map(|r| r.latency_ms).sum::<f64>() / llm_results.len() as f64;

        let avg_cratesio_p1 = cratesio_results
            .iter()
            .map(|r| r.precision_at_1)
            .sum::<f64>()
            / cratesio_results.len() as f64;
        let avg_cratesio_p5 = cratesio_results
            .iter()
            .map(|r| r.precision_at_5)
            .sum::<f64>()
            / cratesio_results.len() as f64;
        let avg_cratesio_p10 = cratesio_results
            .iter()
            .map(|r| r.precision_at_10)
            .sum::<f64>()
            / cratesio_results.len() as f64;
        let avg_cratesio_p20 = cratesio_results
            .iter()
            .map(|r| r.precision_at_20)
            .sum::<f64>()
            / cratesio_results.len() as f64;
        let avg_cratesio_relevant = cratesio_results
            .iter()
            .map(|r| r.relevant_count)
            .sum::<i32>() as f64
            / cratesio_results.len() as f64;
        let avg_cratesio_latency = cratesio_results.iter().map(|r| r.latency_ms).sum::<f64>()
            / cratesio_results.len() as f64;

        println!("\nğŸ“ˆ å¹³å‡æ€§èƒ½:");
        println!(
            "  LLMè¾…åŠ©æœç´¢: P@1={:.4}, P@5={:.4}, P@10={:.4}, P@20={:.4}, ç›¸å…³={:.1}, å»¶è¿Ÿ={:.1}ms",
            avg_llm_p1, avg_llm_p5, avg_llm_p10, avg_llm_p20, avg_llm_relevant, avg_llm_latency
        );
        println!(
            "  crates.io:   P@1={:.4}, P@5={:.4}, P@10={:.4}, P@20={:.4}, ç›¸å…³={:.1}, å»¶è¿Ÿ={:.1}ms",
            avg_cratesio_p1,
            avg_cratesio_p5,
            avg_cratesio_p10,
            avg_cratesio_p20,
            avg_cratesio_relevant,
            avg_cratesio_latency
        );

        // è®¡ç®—æå‡ç™¾åˆ†æ¯”
        if avg_cratesio_p1 > 0.0
            && avg_cratesio_p5 > 0.0
            && avg_cratesio_p10 > 0.0
            && avg_cratesio_p20 > 0.0
            && avg_cratesio_relevant > 0.0
        {
            let p1_improve = (avg_llm_p1 / avg_cratesio_p1 - 1.0) * 100.0;
            let p5_improve = (avg_llm_p5 / avg_cratesio_p5 - 1.0) * 100.0;
            let p10_improve = (avg_llm_p10 / avg_cratesio_p10 - 1.0) * 100.0;
            let p20_improve = (avg_llm_p20 / avg_cratesio_p20 - 1.0) * 100.0;
            let relevant_improve = (avg_llm_relevant / avg_cratesio_relevant - 1.0) * 100.0;

            println!("\nğŸš€ LLMè¾…åŠ©æœç´¢ç›¸æ¯”crates.ioçš„æå‡:");
            println!("  P@1: {:+.1}%", p1_improve);
            println!("  P@5: {:+.1}%", p5_improve);
            println!("  P@10: {:+.1}%", p10_improve);
            println!("  P@20: {:+.1}%", p20_improve);
            println!("  ç›¸å…³ç»“æœæ•°é‡: {:+.1}%", relevant_improve);
        }
    }
}

// è¾…åŠ©å‡½æ•°ï¼šæˆªæ–­æ–‡æœ¬
fn truncate_text(s: &str, max_chars: usize) -> String {
    let chars: Vec<char> = s.chars().collect();

    if chars.len() <= max_chars {
        s.to_string()
    } else {
        chars.into_iter().take(max_chars).collect::<String>() + "..."
    }
}
